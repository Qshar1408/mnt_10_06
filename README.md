# Домашнее задание к занятию 17 «Инцидент-менеджмент»

### Грибанов Антон. FOPS-31

## Задание

Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

Информацию о сбое можно изучить по ссылкам ниже:

* [краткое описание на русском языке](https://habr.com/ru/post/427301/);
* [развёрнутое описание на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).


### Постмортем: Сбой доступности GitHub.com

Дата инцидента: 21 октября 2018, 22:52 UTC

Дата полного восстановления: 22 октября 2018, 23:03 UTC

Продолжительность: ~24 часа (с периодическими нарушениями)

Влияние: Значительная деградация сервиса и периодическая полная недоступность GitHub.com, GitHub Enterprise, доставки веб-хуков, сборки страниц GitHub Pages и других зависимых сервисов.

#### Краткое описание
В ходе планового технического обслуживания по замене вышедшего из строя оптического оборудования в одном из дата-центров Восточного побережья США была допущена ошибка, приведшая к рассинхронизации внутренней сети передачи данных (WAN). Это вызвало каскадный отказ, который привел к разделению кластеров баз данных и потере целостности данных. Восстановление требовало скоординированных действий по остановке всего платформы, проверке целостности данных и осторожному, пошаговому возвращению в онлайн, чтобы избежать дальнейшей коррупции данных.

#### Коренные причины

##### Прямая причина: 
Ошибка при выполнении сценария обслуживания (orchestrator), который должен был безопасно перенастроить топологию репликации MySQL. Вместо планового переключения на новый мастер, сценарий некорректно назначил мастером одну из реплик в другом дата-центре, создав ситуацию с двумя активными мастерами (split-brain).

##### Системная причина: 
Отсутствие механизмов блокировки (lockdown или maintenance mode) для критически важных систем, таких как топология баз данных, во время проведения высокорисковых операций. Существующие процедуры не учитывали сценарий столь катастрофического отказа.

##### Глубинная причина: 
Недостаточная отказоустойчивость архитектуры WAN-сети и системы управления базами данных к одновременному отказу нескольких каналов связи. Система не была спроектирована, чтобы элегантно пережить такое масштабное сетевое разделение.

#### Хронология событий
22:52 UTC: Начало планового технического обслуживания для замены неисправного сетевого оборудования в дата-центре US East.

23:02 UTC: Ошибка в сценарии orchestrator привела к рассинхронизации топологии MySQL. В течение 43 секунд произошло 18 ненамеренных переключений мастера, что вызвало неконсистентность данных.

23:07 UTC: Мониторинг зафиксировал резкий рост ошибок и латентности. Инженеры начали расследование.

23:09 UTC: Обнаружена рассинхронизация данных между кластерами баз данных. Было принято решение остановить обработку трафика на сайт (github.com вернул статус 500) для предотвращения дальнейшей порчи данных.

23:19 UTC: Команда приняла решение о переводе всей платформы в режим обслуживания (оранжевый экран) для остановки всех операций записи.

~00:00 - 18:00 UTC (22 окт): Команда вручную проверяла целостность данных для тысяч баз данных и миллионов реплик. Процесс был крайне трудоемким из-за масштаба платформы и необходимости гарантировать консистентность.

18:00 UTC (22 окт): После подтверждения целостности основных кластеров началось осторожное восстановление сервиса в режиме "только чтение".

21:00 UTC: Были восстановлены операции записи, включая пуши коммитов, создание Issues и Pull Requests.

23:03 UTC: Все сервисы, включая отставшие веб-хуки и сборки Pages, были полностью восстановлены. Режим обслуживания снят.

#### Влияние
    * Доступность: Основной сайт github.com был полностью недоступен или работал с серьезными перебоями в течение 6 часов. Деградация сервиса и периодические отключения продолжались в течение 24 часов.
    * Данные: На короткий период существовала угроза потери данных (например, пуши, не попавшие в итоговый мастер). Восстановительные процедуры позволили минимизировать этот риск.
    * Доверие: Инцидент получил широкий резонанс, подорвав доверие пользователей к надежности платформы. Многие проекты с непрерывной интеграцией и развертыванием были заблокированы.

#### Выводы и действия по исправлению
GitHub сформулировал три ключевых направления для улучшений:

1. Улучшение процедур обслуживания и отказоустойчивости:
* Внедрение "режима обслуживания" для топологии БД: Создание механизма, который бы явно блокировал автоматические переключения мастера во время плановых работ.
* Улучшение процедур проверки перед выполнением: Добавление дополнительных проверок "здравого смысла" в автоматизированные сценарии (orchestrator), чтобы предотвратить абсурдные конфигурации.
* Упрощение и документирование процедур восстановления: Создание четких и проверенных runbook для действий в случае потери консистентности данных.

2. Улучшение инструментов и автоматизации для восстановления:
* Инвестиции в инструменты проверки целостности данных: Разработка более быстрых и автоматизированных способов проверки консистентности данных между кластерами.
* Улучшение процедур резервного копирования и восстановления: Ускорение и повышение надежности процессов восстановления из бэкапов на случай критического сбоя.

3. Улучшение архитектуры для устранения единых точек отказа:
* Устранение зависимости от надежности WAN: Пересмотр архитектуры, чтобы сделать каждый дата-центр более независимым и устойчивым к сбоям связи между ЦОД.
* Тестирование на устойчивость (Chaos Engineering): Регулярное проведение учений, моделирующих сбои сетевого оборудования и разделение кластеров БД, чтобы выявлять слабые места в архитектуре и процедурах.

#### Заключение
Инцидент 21 октября 2018 года стал для GitHub суровым, но ценным уроком. Он продемонстрировал, что даже в высоконадежных, отлично спроектированных системах плановое обслуживание может привести к непредвиденным каскадным отказам. Ключевым выводом является необходимость не только в надежной архитектуре, но и в столь же надежных, продуманных и проверенных процедурах для операций, особенно тех, что затрагивают самые критичные компоненты системы, такие как базы данных. Прозрачность, с которой GitHub опубликовал этот постмортем, стала образцом для подражания в индустрии.
